{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7d525e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env ÌùêÎ¶Ñ Ï†ïÎ¶¨\n",
    "-CMOSTConfig: CMOST13.mat Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÌõÑ ÌôïÎ•†ÌëúÎûë value Îî∞Ïò§Í∏∞. \n",
    "-> interpolate=ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Í∞Ä 1,20 20Í∞úÎ∞ñÏóê ÏóÜÏñ¥ÏÑú interpolation ÏÇ¨Ïö©Ìï¥ÏÑú 100ÏÑ∏ÍπåÏßÄ Ïù¥Ïö©Ìï¥Ïïº Ìï®. \n",
    "-> CMOST13.matÏóê ÏûàÎäî Î≥ÄÏàòÎì§ÏùÄ Ï¥ù 81Í∞úÎ°ú ÌïÑÏöîÌïúÍ±∞ calibration ÎΩëÏïÑÏÑú ÌïòÎ©¥ Îê†ÎìØ. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f25c5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "\n",
    "class CMOSTConfig:\n",
    "    def __init__(self, mat_file_path='/Users/llnnseoii/Desktop/cmost/Settings/CMOST13.mat'):\n",
    "        print(f\"üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\")\n",
    "        \n",
    "        try:\n",
    "            mat_data = scipy.io.loadmat(mat_file_path)\n",
    "            if 'temp' in mat_data:\n",
    "                self.data = mat_data['temp'][0, 0]\n",
    "        except:\n",
    "            self.data = None\n",
    "\n",
    "        if self.data is not None:\n",
    "            # =========================================================\n",
    "            # üéõÔ∏è [ÌïµÏã¨ ÏàòÏ†ï] Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ìå©ÌÑ∞ (Calibration Factor)\n",
    "            # =========================================================\n",
    "            # Î™©Ìëú: Î∞úÎ≥ëÎ•† 40% -> 5% (ÏïΩ 1/8Î°ú Í∞êÏÜå ÌïÑÏöî)\n",
    "            # 0.15 (15%)Î°ú ÏÑ§Ï†ïÌïòÏó¨ Î∞úÎ≥ë ÌôïÎ•†ÏùÑ Ìôï ÎÇÆÏ∂•ÎãàÎã§.\n",
    "            CALIB_FACTOR = 0.15 \n",
    "            \n",
    "            self.frac_female = self._get_scalar('fraction_female')\n",
    "            \n",
    "            # ÎÇ®ÏÑ± Îç∞Ïù¥ÌÑ∞ (Î≥¥Ï†ï Ï†ÅÏö©)\n",
    "            self.male_onset = self._interpolate(self.data['NewPolypRate']) * CALIB_FACTOR\n",
    "            self.male_early = self._interpolate(self.data['EarlyProgressionRate'])\n",
    "            self.male_adv   = self._interpolate(self.data['AdvancedProgressionRate'])\n",
    "            self.male_life  = self.data['LifeTable'][:, 0]\n",
    "            \n",
    "            # Ïó¨ÏÑ± Îç∞Ïù¥ÌÑ∞ (Î≥¥Ï†ï Ï†ÅÏö©)\n",
    "            if 'new_polyp_female' in self.data.dtype.names:\n",
    "                self.female_onset = self._interpolate(self.data['new_polyp_female']) * CALIB_FACTOR\n",
    "                self.female_early = self._interpolate(self.data['early_progression_female'])\n",
    "                self.female_adv   = self._interpolate(self.data['advanced_progression_female'])\n",
    "                self.female_life  = self.data['LifeTable'][:, 1]\n",
    "            else:\n",
    "                self.female_onset = self.male_onset\n",
    "                self.female_early = self.male_early\n",
    "                self.female_adv   = self.male_adv\n",
    "                self.female_life  = self.male_life\n",
    "\n",
    "            self.prob_healing = self.data['Healing'].flatten()\n",
    "            \n",
    "            # Í∏âÏÜç ÏïîÎèÑ ÎÑàÎ¨¥ ÏûêÏ£º ÏÉùÍ∏∞Î©¥ Ïïà ÎêòÎØÄÎ°ú ÎèôÏùºÌïòÍ≤å Î≥¥Ï†ï\n",
    "            self.prob_fast_cancer = self.data['FastCancer'].flatten() * CALIB_FACTOR\n",
    "            self.prob_symptoms = self.data['Symptoms'].flatten()\n",
    "            \n",
    "            # Risk Ï†ïÍ∑úÌôî\n",
    "            raw_risk = self.data['IndividualRisk'].flatten()\n",
    "            mean_risk = np.mean(raw_risk) if len(raw_risk) > 0 else 1.0\n",
    "            self.risk_dist = raw_risk / mean_risk \n",
    "            self.risk_dist = np.clip(self.risk_dist, 0.1, 5.0) \n",
    "\n",
    "            self.sens_colo = self.data['Colo_Detection'].flatten()\n",
    "            self.risk_perf  = self._get_scalar('Colonoscopy_RiscPerforation')\n",
    "            self.death_perf = self._get_scalar('DeathPerforation')\n",
    "        else:\n",
    "            self._set_dummy_values()\n",
    "\n",
    "        self.sens_fobt = np.array([0.02, 0.02, 0.05, 0.05, 0.12, 0.12, 0.4, 0.4, 0.4, 0.4])\n",
    "\n",
    "        # Î≥¥ÏÉÅ Ï≤¥Í≥Ñ (ÌïúÍµ≠Ìòï ÎπÑÏö© Î∞òÏòÅ Î≤ÑÏ†Ñ Ïú†ÏßÄ)\n",
    "        self.rewards = {\n",
    "            'cost_wait': 0.0,\n",
    "            'cost_fobt': 0.1,  \n",
    "            'cost_colo': 2.0,  \n",
    "            'cost_sigmo': 1.2,\n",
    "            'reward_alive': 1.0,       \n",
    "            'reward_polyp': 5.0,       \n",
    "            'reward_cancer': 200.0,     \n",
    "            'penalty_death': -8000.0,  \n",
    "            'penalty_complication': -100.0 \n",
    "        }\n",
    "\n",
    "    # ... (ÎÇòÎ®∏ÏßÄ Ìó¨Ìçº Ìï®ÏàòÎäî ÎèôÏùº) ...\n",
    "    def _get_scalar(self, key):\n",
    "        if key in self.data.dtype.names:\n",
    "            val = self.data[key]\n",
    "            return val.item() if val.size == 1 else val.flatten()[0]\n",
    "        return 0.0\n",
    "\n",
    "    def _interpolate(self, raw_data, target_len=100):\n",
    "        if raw_data is None or raw_data.size == 0: return np.zeros(target_len)\n",
    "        y = raw_data.flatten()\n",
    "        x = np.linspace(0, target_len, len(y))\n",
    "        return np.interp(np.arange(target_len), x, y)\n",
    "    \n",
    "    def _set_dummy_values(self):\n",
    "        self.risk_dist = np.ones(100)\n",
    "    \n",
    "    def get_rates(self, is_female):\n",
    "        if is_female: return self.female_onset, self.female_early, self.female_adv, self.female_life\n",
    "        return self.male_onset, self.male_early, self.male_adv, self.male_life\n",
    "    \n",
    "    def get_sensitivity(self, test_type, state_idx):\n",
    "        if state_idx < 0: return 0\n",
    "        idx = min(state_idx, 9)\n",
    "        if test_type == 'colonoscopy': return self.sens_colo[idx]\n",
    "        elif test_type == 'fobt': return self.sens_fobt[idx]\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. CMOST Environment (ÏãúÎÆ¨Î†àÏù¥ÏÖò ÌôòÍ≤Ω)\n",
    "# ==============================================================================\n",
    "class CmostEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(CmostEnv, self).__init__()\n",
    "        self.cfg = CMOSTConfig() \n",
    "\n",
    "        #Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ùÏö© Ï∂úÎ†•\n",
    "        print(f\"üîç [Data Check] Male Onset Rate (Age 50): {self.cfg.male_onset[50]:.5f}\")\n",
    "        print(f\"üîç [Data Check] Sensitivity (Polyp Size 5): {self.cfg.sens_colo[5]:.5f}\")\n",
    "\n",
    "\n",
    "        \n",
    "        # Action Space: 0=Wait, 1=I-FOBT, 2=Colonoscopy, 3=Sigmoidoscopy\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # Observation Space\n",
    "        # [ÎÇòÏù¥, ÏÑ±Î≥Ñ, Ï¶ùÏÉÅ, ÎßàÏßÄÎßâÍ≤ÄÏÇ¨, Í≤∞Í≥º, Í≤ΩÍ≥ºÏãúÍ∞Ñ]\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(6,), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        max_retries = 100 \n",
    "        attempt = 0\n",
    "        \n",
    "        while attempt < max_retries:\n",
    "            attempt += 1\n",
    "            \n",
    "            # 1. Ï¥àÍ∏∞Ìôî\n",
    "            self.max_age = 100\n",
    "            self.is_female = np.random.rand() < self.cfg.frac_female\n",
    "            self.risk_factor = np.random.choice(self.cfg.risk_dist)\n",
    "            \n",
    "            self.rates = self.cfg.get_rates(self.is_female) \n",
    "            self.r_onset, self.r_early, self.r_adv, self.r_life = self.rates\n",
    "\n",
    "            self.hidden_polyps = []   \n",
    "            self.hidden_cancer = None \n",
    "            \n",
    "            # 2. Warm-up (0ÏÑ∏ -> 50ÏÑ∏)\n",
    "            self.age = 0\n",
    "            target_start_age = 50\n",
    "            is_dead_during_warmup = False\n",
    "            \n",
    "            for _ in range(target_start_age):\n",
    "                for q in range(4):\n",
    "                    current_time = self.age + q/4.0\n",
    "                    self._update_biology_quarterly(current_time)\n",
    "                    if self._check_death(current_time): \n",
    "                        is_dead_during_warmup = True\n",
    "                        break\n",
    "                if is_dead_during_warmup: break\n",
    "                self.age += 1\n",
    "                \n",
    "            # 3. Ï°∞Í±¥ ÌôïÏù∏ (ÏÇ¥ÏïÑÏûàÍ≥†, ÎßêÍ∏∞Ïïî ÏïÑÎãàÎ©¥ ÌÜµÍ≥º)\n",
    "            if not is_dead_during_warmup:\n",
    "                if not (self.hidden_cancer and self.hidden_cancer >= 4):\n",
    "                    break \n",
    "        \n",
    "        # Ïã§Ìå® Ïãú Í∞ïÏ†ú Ï¥àÍ∏∞Ìôî (ÏïàÏ†ÑÏû•Ïπò)\n",
    "        if attempt >= max_retries:\n",
    "            self.age = 50\n",
    "            self.hidden_polyps = []\n",
    "            self.hidden_cancer = None \n",
    "        \n",
    "        # Í¥ÄÏ∏°Í∞í Ï¥àÍ∏∞Ìôî\n",
    "        self.last_test_type = 0\n",
    "        self.last_test_result = 0\n",
    "        self.time_since_test = 10.0 \n",
    "        self.has_symptom = 0\n",
    "        \n",
    "        if self.hidden_cancer:\n",
    "             symp_prob = self.cfg.prob_symptoms[min(5+self.hidden_cancer, 9)]\n",
    "             if np.random.rand() < symp_prob:\n",
    "                 self.has_symptom = 1\n",
    "\n",
    "        # ‚òÖ‚òÖ‚òÖ [ÏàòÏ†ï] return Íµ¨Î¨∏ ÏúÑÏπò Î∞è Îì§Ïó¨Ïì∞Í∏∞ ÌôïÏù∏ ‚òÖ‚òÖ‚òÖ\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {'cause': 'alive', 'action': action}\n",
    "        \n",
    "        # 1. Action\n",
    "        if not done:\n",
    "            reward_act, done_act, info_act = self._perform_action(action)\n",
    "            reward += reward_act\n",
    "            if done_act: \n",
    "                done = True\n",
    "                info.update(info_act)\n",
    "\n",
    "        # 2. Biology (Quarterly)\n",
    "        if not done:\n",
    "            for q in range(4):\n",
    "                current_time = self.age + q/4.0\n",
    "                self._update_biology_quarterly(current_time)\n",
    "                \n",
    "                if self.hidden_cancer:\n",
    "                    symp_prob = self.cfg.prob_symptoms[min(5+self.hidden_cancer, 9)] / 4.0\n",
    "                    if np.random.rand() < symp_prob:\n",
    "                        self.has_symptom = 1\n",
    "                \n",
    "                if self._check_death(current_time):\n",
    "                    done = True\n",
    "                    # Ïïî ÏÇ¨Îßù vs ÏûêÏó∞ÏÇ¨ Íµ¨Î∂Ñ\n",
    "                    if self.hidden_cancer and self.has_symptom:\n",
    "                        info['cause'] = 'cancer_death'\n",
    "                        reward += self.cfg.rewards['penalty_death']\n",
    "                    else:\n",
    "                        info['cause'] = 'natural_death'\n",
    "                    break\n",
    "\n",
    "        # 3. Year End\n",
    "        if not done:\n",
    "            self.age += 1\n",
    "            reward += self.cfg.rewards['reward_alive']\n",
    "            self.time_since_test += 1\n",
    "            if self.age >= self.max_age:\n",
    "                done = True\n",
    "                info['cause'] = 'max_age_reached'\n",
    "\n",
    "        return self._get_obs(), reward, done, False, info\n",
    "\n",
    "    def _perform_action(self, action):\n",
    "        r, d = 0, False\n",
    "        i = {}\n",
    "        \n",
    "        if action == 0: # Wait\n",
    "            return r, d, i\n",
    "            \n",
    "        elif action == 1: # I-FOBT (FIT)\n",
    "            r -= 0.5 \n",
    "            self.time_since_test = 0\n",
    "            self.last_test_type = 0.3\n",
    "            detected, f_type = self._run_test('fobt', remove=False, sens_factor=1.5)\n",
    "            if detected:\n",
    "                self.last_test_result = f_type\n",
    "                r += 0.5 \n",
    "            else:\n",
    "                self.last_test_result = 0\n",
    "                \n",
    "        elif action == 2: # Colonoscopy\n",
    "            r -= 5.0 \n",
    "            self.time_since_test = 0\n",
    "            self.last_test_type = 1.0\n",
    "            \n",
    "            if np.random.rand() < self.cfg.risk_perf:\n",
    "                r += self.cfg.rewards['penalty_complication']\n",
    "                if np.random.rand() < self.cfg.death_perf:\n",
    "                    return r + self.cfg.rewards['penalty_death'], True, {'cause': 'perforation_death'}\n",
    "\n",
    "            detected, f_type = self._run_test('colonoscopy', remove=True)\n",
    "            if detected:\n",
    "                self.last_test_result = f_type\n",
    "                if f_type == 1: r += self.cfg.rewards['reward_polyp']\n",
    "                elif f_type == 2:\n",
    "                    r += self.cfg.rewards['reward_cancer']\n",
    "                    d = True\n",
    "                    i['cause'] = 'cancer_detected'\n",
    "            else:\n",
    "                self.last_test_result = 0\n",
    "\n",
    "        elif action == 3: # Sigmoidoscopy\n",
    "            r -= 2.0 \n",
    "            self.time_since_test = 0\n",
    "            self.last_test_type = 0.6\n",
    "            \n",
    "            detected, f_type = self._run_test('colonoscopy', remove=True, reach_factor=0.6)\n",
    "            if detected:\n",
    "                self.last_test_result = f_type\n",
    "                if f_type == 1: r += self.cfg.rewards['reward_polyp']\n",
    "                elif f_type == 2:\n",
    "                    r += self.cfg.rewards['reward_cancer']\n",
    "                    d = True\n",
    "                    i['cause'] = 'cancer_detected'\n",
    "            else:\n",
    "                self.last_test_result = 0\n",
    "                \n",
    "        return r, d, i\n",
    "\n",
    "    def _run_test(self, t_type, remove, sens_factor=1.0, reach_factor=1.0):\n",
    "        det, f_type = False, 0\n",
    "        \n",
    "        # Ïïî ÌÉêÏßÄ\n",
    "        if self.hidden_cancer:\n",
    "            if np.random.rand() < reach_factor: \n",
    "                sens = self.cfg.get_sensitivity(t_type, 5 + self.hidden_cancer) * sens_factor\n",
    "                if np.random.rand() < sens: return True, 2\n",
    "            \n",
    "        # Ïö©Ï¢Ö ÌÉêÏßÄ\n",
    "        rem_idx = []\n",
    "        for idx, size in enumerate(self.hidden_polyps):\n",
    "            if np.random.rand() < reach_factor: \n",
    "                sens = self.cfg.get_sensitivity(t_type, min(size-1, 5)) * sens_factor\n",
    "                if np.random.rand() < sens:\n",
    "                    det = True\n",
    "                    f_type = 1\n",
    "                    rem_idx.append(idx)\n",
    "        \n",
    "        if remove and rem_idx:\n",
    "            for idx in sorted(rem_idx, reverse=True):\n",
    "                self.hidden_polyps.pop(idx)\n",
    "                \n",
    "        return det, f_type\n",
    "\n",
    "    def _update_biology_quarterly(self, current_time):\n",
    "        age_idx = min(int(self.age), 99)\n",
    "        dt = 0.25 \n",
    "        \n",
    "        prob_onset = (self.r_onset[age_idx] * self.risk_factor) * dt\n",
    "        if np.random.rand() < prob_onset:\n",
    "            self.hidden_polyps.append(1) \n",
    "\n",
    "        prob_fast = self.cfg.prob_fast_cancer[age_idx] if age_idx < len(self.cfg.prob_fast_cancer) else 0\n",
    "        if np.random.rand() < prob_fast * dt:\n",
    "            self.hidden_cancer = 1 \n",
    "            \n",
    "        for i in range(len(self.hidden_polyps)):\n",
    "            size = self.hidden_polyps[i]\n",
    "            rate = self.r_early[age_idx] if size <= 3 else self.r_adv[age_idx]\n",
    "            if np.random.rand() < rate * dt: \n",
    "                self.hidden_polyps[i] += 1\n",
    "\n",
    "        for i in reversed(range(len(self.hidden_polyps))):\n",
    "            size = self.hidden_polyps[i]\n",
    "            heal_prob = self.cfg.prob_healing[min(size-1, 9)] if size > 0 else 0\n",
    "            if np.random.rand() < heal_prob * dt:\n",
    "                self.hidden_polyps[i] -= 1 \n",
    "                if self.hidden_polyps[i] <= 0:\n",
    "                    self.hidden_polyps.pop(i) \n",
    "\n",
    "        for i in reversed(range(len(self.hidden_polyps))):\n",
    "            if self.hidden_polyps[i] > 6: \n",
    "                if self.hidden_cancer is None: self.hidden_cancer = 1\n",
    "                self.hidden_polyps.pop(i)\n",
    "\n",
    "        if self.hidden_cancer and self.hidden_cancer < 4:\n",
    "            if np.random.rand() < 0.4 * dt: \n",
    "                self.hidden_cancer += 1\n",
    "\n",
    "    def _check_death(self, current_time):\n",
    "        age_idx = min(int(self.age), 99)\n",
    "        nat_death_prob = self.r_life[age_idx] / 4.0\n",
    "        if np.random.rand() < nat_death_prob: return True\n",
    "            \n",
    "        if self.hidden_cancer:\n",
    "            cancer_death_base = [0, 0.01, 0.05, 0.2, 0.8] \n",
    "            c_death = cancer_death_base[self.hidden_cancer] / 4.0\n",
    "            if np.random.rand() < c_death: return True\n",
    "        return False\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([\n",
    "            (self.age - 50) / 50.0,      \n",
    "            1.0 if self.is_female else 0.0,\n",
    "            self.has_symptom,\n",
    "            self.last_test_type,\n",
    "            self.last_test_result,\n",
    "            min(self.time_since_test, 10) / 10.0\n",
    "        ], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68fe4552",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\n",
      "ü§ñ PPO Î™®Îç∏ ÏÉùÏÑ± Î∞è ÌïôÏäµ ÏãúÏûë...\n",
      "Using cpu device\n",
      "üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\n",
      "\n",
      "--- [Random Agent] ÌèâÍ∞Ä ÏãúÏûë (20Î™Ö) ---\n",
      "ÌèâÍ∑† Î≥¥ÏÉÅ: -4.60\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 7629 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5097       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 0          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01718703 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.000223   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 155        |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    value_loss           | 279        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4718        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020959346 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4407        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023731714 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4321       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01599929 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.0255     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 226        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 480        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4269        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014241749 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.00206    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58e+05    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    value_loss           | 2.56e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4242        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017919324 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 387         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    value_loss           | 457         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4232        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016790843 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | 0.0686      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4217       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00957403 |\n",
      "|    clip_fraction        | 0.0585     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.756     |\n",
      "|    explained_variance   | 0.094      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 295        |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00472   |\n",
      "|    value_loss           | 603        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4209        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003257326 |\n",
      "|    clip_fraction        | 0.00425     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | -0.00248    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+05    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000475   |\n",
      "|    value_loss           | 5.46e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4198        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124476 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.0956      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 449         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 406         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4190        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005194381 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4182         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023545127 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | -0.00135     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.42e+04     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | 0.000685     |\n",
      "|    value_loss           | 2.63e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4174         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014205535 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.00172      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.2         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 0.00134      |\n",
      "|    value_loss           | 3.1e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4173         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008063214 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5            |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4162         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034579965 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.353       |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 157          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4151          |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028638594 |\n",
      "|    clip_fraction        | 0.00283       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.351        |\n",
      "|    explained_variance   | 0.154         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 13.4          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000511     |\n",
      "|    value_loss           | 201           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4126         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009376682 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.316       |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 284          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4085          |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016498647 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.32         |\n",
      "|    explained_variance   | 0.000175      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 313           |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000105     |\n",
      "|    value_loss           | 3.08e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4077          |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072440447 |\n",
      "|    clip_fraction        | 0.011         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.316        |\n",
      "|    explained_variance   | -0.00213      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.29          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -7.96e-05     |\n",
      "|    value_loss           | 8.51e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4066         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012849325 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.267       |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 248          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4061        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.29308e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.00144     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.15e+05    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.000307   |\n",
      "|    value_loss           | 3.07e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4065        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002087467 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4068       |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00103811 |\n",
      "|    clip_fraction        | 0.00757    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.195     |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00105   |\n",
      "|    value_loss           | 69.1       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4074          |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072866085 |\n",
      "|    clip_fraction        | 0.00864       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.199        |\n",
      "|    explained_variance   | 0.479         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 15.7          |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | 0.000207      |\n",
      "|    value_loss           | 33.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4078          |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093581836 |\n",
      "|    clip_fraction        | 0.0131        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.165        |\n",
      "|    explained_variance   | 0.572         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 20.3          |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000785     |\n",
      "|    value_loss           | 29.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4082          |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0115596e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.162        |\n",
      "|    explained_variance   | 3.15e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 46.6          |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | 7.71e-05      |\n",
      "|    value_loss           | 4.39e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4085         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008283213 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.176       |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.81         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4088          |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081545167 |\n",
      "|    clip_fraction        | 0.00728       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.172        |\n",
      "|    explained_variance   | 0.233         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 17.6          |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    value_loss           | 132           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4091         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007225945 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | -0.000137    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000651    |\n",
      "|    value_loss           | 2.62e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4089          |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094556174 |\n",
      "|    clip_fraction        | 0.0123        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.165        |\n",
      "|    explained_variance   | -0.000383     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 93.8          |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.000713     |\n",
      "|    value_loss           | 2.43e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4089         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006823172 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.146       |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56.6         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000341    |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4080         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005654458 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | -0.00116     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.85e+05     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000166    |\n",
      "|    value_loss           | 1.93e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4081         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006100511 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.143       |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000182    |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4074          |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021290063 |\n",
      "|    clip_fraction        | 0.00601       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.158        |\n",
      "|    explained_variance   | 0.592         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 17.1          |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.000315     |\n",
      "|    value_loss           | 32.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4073          |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066753395 |\n",
      "|    clip_fraction        | 0.014         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.125        |\n",
      "|    explained_variance   | 0.296         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 23.2          |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    value_loss           | 116           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4069          |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041946943 |\n",
      "|    clip_fraction        | 0.00576       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.106        |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.000554     |\n",
      "|    value_loss           | 29.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4063        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000677571 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0956     |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4062          |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029325954 |\n",
      "|    clip_fraction        | 0.00405       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0842       |\n",
      "|    explained_variance   | 0.00515       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.64e+05      |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000729     |\n",
      "|    value_loss           | 1.28e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4064          |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036026593 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0847       |\n",
      "|    explained_variance   | 0.00152       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 18.5          |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | 3.18e-05      |\n",
      "|    value_loss           | 2.76e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4063          |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019047153 |\n",
      "|    clip_fraction        | 0.00239       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.065        |\n",
      "|    explained_variance   | 0.302         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 20.9          |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | 0.000536      |\n",
      "|    value_loss           | 126           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4065          |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9220246e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0663       |\n",
      "|    explained_variance   | 0.00687       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.3e+05       |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -2.25e-06     |\n",
      "|    value_loss           | 4.54e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4067          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011359985 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.069        |\n",
      "|    explained_variance   | 0.00293       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.4e+05       |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -4.83e-05     |\n",
      "|    value_loss           | 2.04e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4068         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007660267 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0696      |\n",
      "|    explained_variance   | 0.00326      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.83         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000475    |\n",
      "|    value_loss           | 1.47e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4071          |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020302541 |\n",
      "|    clip_fraction        | 0.0043        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0875       |\n",
      "|    explained_variance   | 0.409         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.000215     |\n",
      "|    value_loss           | 32.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4072          |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022743637 |\n",
      "|    clip_fraction        | 0.00562       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0828       |\n",
      "|    explained_variance   | 0.465         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 21.9          |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.000282     |\n",
      "|    value_loss           | 37.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4073          |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 96256         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010848339 |\n",
      "|    clip_fraction        | 0.00352       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0957       |\n",
      "|    explained_variance   | 0.00268       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 24.6          |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -0.000437     |\n",
      "|    value_loss           | 2.62e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 4069          |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031530336 |\n",
      "|    clip_fraction        | 0.00771       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0987       |\n",
      "|    explained_variance   | 0.264         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 151           |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000861     |\n",
      "|    value_loss           | 154           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4069         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.004128e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.00265      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+06     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 4.4e-05      |\n",
      "|    value_loss           | 6.04e+05     |\n",
      "------------------------------------------\n",
      "‚úÖ ÌïôÏäµ ÏôÑÎ£å!\n",
      "üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\n",
      "\n",
      "--- [Trained AI] ÌèâÍ∞Ä ÏãúÏûë (20Î™Ö) ---\n",
      "ÌèâÍ∑† Î≥¥ÏÉÅ: -371.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-371.35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. ÌïôÏäµ Î∞è ÌèâÍ∞Ä ÏΩîÎìú\n",
    "# ==============================================================================\n",
    "def evaluate_agent(agent_model, num_episodes=50, name=\"Agent\"):\n",
    "    test_env = CmostEnv()\n",
    "    rewards = []\n",
    "    \n",
    "    print(f\"\\n--- [{name}] ÌèâÍ∞Ä ÏãúÏûë ({num_episodes}Î™Ö) ---\")\n",
    "    for ep in range(num_episodes):\n",
    "        obs, _ = test_env.reset()\n",
    "        done = False\n",
    "        ep_reward = 0\n",
    "        while not done:\n",
    "            if agent_model: action, _ = agent_model.predict(obs, deterministic=True)\n",
    "            else: action = test_env.action_space.sample()\n",
    "            obs, reward, done, _, info = test_env.step(action)\n",
    "            ep_reward += reward\n",
    "        rewards.append(ep_reward)\n",
    "    \n",
    "    print(f\"ÌèâÍ∑† Î≥¥ÏÉÅ: {np.mean(rewards):.2f}\")\n",
    "    return np.mean(rewards)\n",
    "\n",
    "# ÌïôÏäµ ÏãúÏûë\n",
    "env = DummyVecEnv([lambda: CmostEnv()])\n",
    "print(\"ü§ñ PPO Î™®Îç∏ ÏÉùÏÑ± Î∞è ÌïôÏäµ ÏãúÏûë...\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.0003, gamma=0.999)\n",
    "evaluate_agent(None, num_episodes=20, name=\"Random Agent\")\n",
    "model.learn(total_timesteps=100000) \n",
    "print(\"‚úÖ ÌïôÏäµ ÏôÑÎ£å!\")\n",
    "evaluate_agent(model, num_episodes=20, name=\"Trained AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f79f313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ ÎπÑÍµê Î∂ÑÏÑù ÏãúÏûë...\n",
      "üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\n",
      "üè• [Random] 10000Î™Ö ÌôòÏûê ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏßÑÌñâ Ï§ë....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... ÏôÑÎ£å!\n",
      "üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\n",
      "üè• [PPO_AI] 10000Î™Ö ÌôòÏûê ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏßÑÌñâ Ï§ë....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... ÏôÑÎ£å!\n",
      "\n",
      "üìä [ÏµúÏ¢Ö ÏÑ±Ï†ÅÌëú: Random vs AI]\n",
      "============================================================\n",
      "Metric                    | Random Agent    | PPO AI Doctor  \n",
      "------------------------------------------------------------\n",
      "Avg Lifespan (Age)        | 78.2            | 77.7           \n",
      "Cancer Mortality (%)      | 0.0             | 1.0            \n",
      "Medical Accident (%)      | 0.0             | 0.0            \n",
      "Avg Tests (Count)         | 21.9            | 0.0            \n",
      "Total Reward              | -22.5           | -50.7          \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def run_full_evaluation(agent_model, env_class, episodes=100, agent_name=\"Agent\"):\n",
    "    \"\"\"\n",
    "    ÏóêÏù¥Ï†ÑÌä∏Ïùò ÏÑ±Îä•ÏùÑ ÏÉÅÏÑ∏ ÌèâÍ∞ÄÌïòÍ≥†, Í∞úÎ≥Ñ ÌôòÏûê Í∏∞Î°ùÏùÑ Î∞òÌôòÌïòÎäî Ìï®Ïàò\n",
    "    \"\"\"\n",
    "    env = env_class()\n",
    "    records = []\n",
    "    \n",
    "    # ÌÜµÍ≥ÑÏö© Î≥ÄÏàò\n",
    "    total_lifespan = 0\n",
    "    cancer_deaths = 0\n",
    "    perf_deaths = 0\n",
    "    total_rewards = 0\n",
    "    \n",
    "    print(f\"üè• [{agent_name}] {episodes}Î™Ö ÌôòÏûê ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏßÑÌñâ Ï§ë...\", end=\"\")\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # ÌôòÏûêÎ≥Ñ Í∏∞Î°ù\n",
    "        history = {\n",
    "            'id': i + 1,\n",
    "            'agent_type': agent_name,\n",
    "            'risk': env.risk_factor,\n",
    "            'gender': \"Female\" if env.is_female else \"Male\",\n",
    "            'events': [], # (ÎÇòÏù¥, Í≤ÄÏÇ¨Î™Ö)\n",
    "            'cause': None\n",
    "        }\n",
    "        \n",
    "        # ÌñâÎèô Ïù¥Î¶Ñ Îß§Ìïë\n",
    "        action_map = {0: 'Wait', 1: 'I-FOBT', 2: 'Colo', 3: 'Sigmo'}\n",
    "        \n",
    "        while not done:\n",
    "            if agent_model:\n",
    "                action, _ = agent_model.predict(obs, deterministic=True)\n",
    "                action = int(action)\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "            \n",
    "            # Í≤ÄÏÇ¨ Í∏∞Î°ù (ÎåÄÍ∏∞(0) Ï†úÏô∏)\n",
    "            if action > 0:\n",
    "                history['events'].append((env.age, action_map[action]))\n",
    "            \n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            ep_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                history['cause'] = info.get('cause')\n",
    "                total_lifespan += env.age\n",
    "                if info.get('cause') == 'cancer_death': cancer_deaths += 1\n",
    "                if info.get('cause') == 'perforation_death': perf_deaths += 1\n",
    "        \n",
    "        total_rewards += ep_reward\n",
    "        \n",
    "        # --- Îç∞Ïù¥ÌÑ∞ Í∞ÄÍ≥µ (Interval Í≥ÑÏÇ∞) ---\n",
    "        ages = [e[0] for e in history['events']]\n",
    "        methods = [e[1] for e in history['events']]\n",
    "        \n",
    "        if len(ages) > 1:\n",
    "            intervals = np.diff(ages).tolist()\n",
    "            intervals = [int(x) for x in intervals] # ÏÜåÏàòÏ†ê Ï†úÍ±∞\n",
    "            avg_int = round(np.mean(intervals), 1)\n",
    "        else:\n",
    "            intervals = []\n",
    "            avg_int = 0\n",
    "\n",
    "        # Î†àÏΩîÎìú Ï∂îÍ∞Ä\n",
    "        records.append({\n",
    "            \"Agent\": agent_name,\n",
    "            \"ID\": history['id'],\n",
    "            \"Gender\": history['gender'],\n",
    "            \"Risk\": round(history['risk'], 2),\n",
    "            \"Lifespan\": int(env.age),\n",
    "            \"Death Cause\": history['cause'],\n",
    "            \"Total Tests\": len(ages),\n",
    "            \"Methods\": str(methods).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\"),\n",
    "            \"Intervals\": str(intervals).replace(\"[\", \"\").replace(\"]\", \"\"),\n",
    "            \"Avg Interval\": avg_int if avg_int > 0 else \"-\"\n",
    "        })\n",
    "        \n",
    "        if i % 20 == 0: print(\".\", end=\"\")\n",
    "\n",
    "    print(\" ÏôÑÎ£å!\")\n",
    "    \n",
    "    # ÏöîÏïΩ ÌÜµÍ≥Ñ Î∞òÌôò\n",
    "    summary = {\n",
    "        \"Agent\": agent_name,\n",
    "        \"Avg Reward\": total_rewards / episodes,\n",
    "        \"Avg Lifespan\": total_lifespan / episodes,\n",
    "        \"Cancer Mortality (%)\": (cancer_deaths / episodes) * 100,\n",
    "        \"Perforation Death (%)\": (perf_deaths / episodes) * 100,\n",
    "        \"Avg Tests per Patient\": sum(r['Total Tests'] for r in records) / episodes\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(records), summary\n",
    "\n",
    "# =========================================================\n",
    "# 1. Ïã§Ìñâ: Random vs PPO ÎπÑÍµê\n",
    "# =========================================================\n",
    "print(\"\\nüîÑ ÎπÑÍµê Î∂ÑÏÑù ÏãúÏûë...\")\n",
    "df_random, sum_random = run_full_evaluation(None, CmostEnv, episodes=10000, agent_name=\"Random\")\n",
    "df_ppo, sum_ppo = run_full_evaluation(model, CmostEnv, episodes=10000, agent_name=\"PPO_AI\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Í≤∞Í≥º ÎπÑÍµêÌëú Ï∂úÎ†•\n",
    "# =========================================================\n",
    "print(\"\\nüìä [ÏµúÏ¢Ö ÏÑ±Ï†ÅÌëú: Random vs AI]\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} | {'Random Agent':<15} | {'PPO AI Doctor':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Avg Lifespan (Age)':<25} | {sum_random['Avg Lifespan']:<15.1f} | {sum_ppo['Avg Lifespan']:<15.1f}\")\n",
    "print(f\"{'Cancer Mortality (%)':<25} | {sum_random['Cancer Mortality (%)']:<15.1f} | {sum_ppo['Cancer Mortality (%)']:<15.1f}\")\n",
    "print(f\"{'Medical Accident (%)':<25} | {sum_random['Perforation Death (%)']:<15.1f} | {sum_ppo['Perforation Death (%)']:<15.1f}\")\n",
    "print(f\"{'Avg Tests (Count)':<25} | {sum_random['Avg Tests per Patient']:<15.1f} | {sum_ppo['Avg Tests per Patient']:<15.1f}\")\n",
    "print(f\"{'Total Reward':<25} | {sum_random['Avg Reward']:<15.1f} | {sum_ppo['Avg Reward']:<15.1f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# =========================================================\n",
    "# 3. CSV Ï†ÄÏû• (VS Code ÏãúÍ∞ÅÌôîÏö©)\n",
    "# =========================================================\n",
    "# Îëê Îç∞Ïù¥ÌÑ∞ Ìï©ÏπòÍ∏∞\n",
    "df_final = pd.concat([df_random, df_ppo])\n",
    "\n",
    "# ÌïúÍ∏Ä Îß§Ìïë (Î≥¥Í∏∞ Ï¢ãÍ≤å Î≥ÄÌôò)\n",
    "cause_map = {\n",
    "    'natural_death': 'Natural', \n",
    "    'cancer_death': 'Cancer', \n",
    "    'perforation_death': 'Accident', \n",
    "    'cancer_detected': 'Cured',\n",
    "    'max_age_reached': 'MaxAge'\n",
    "}\n",
    "df_final['Death Cause'] = df_final['Death Cause'].map(cause_map).fillna(df_final['Death Cause'])\n",
    "\n",
    "# ÌååÏùº Ï†ÄÏû•\n",
    "file_name = \"comparison_results.csv\"\n",
    "# df_final.to_csv(file_name, index=False)\n",
    "\n",
    "# print(f\"\\n‚úÖ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÏôÑÎ£å: {file_name}\")\n",
    "# print(\"üëâ VS CodeÏóêÏÑú Ïù¥ CSV ÌååÏùºÏùÑ Ïó¥Í≥† 'Data Wrangler' ÎòêÎäî 'Excel Viewer' ÌôïÏû• ÌîÑÎ°úÍ∑∏Îû®ÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ Ìëú/Í∑∏ÎûòÌîÑÎ°ú Î≥º Ïàò ÏûàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c106c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Death Cause\n",
       "Natural     19134\n",
       "Cured         396\n",
       "MaxAge        367\n",
       "Cancer        102\n",
       "Accident        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ìñâ(Row) Ï†úÌïúÏùÑ ÏóÜÏï†Îäî ÏÑ§Ï†ï (None = Ï†úÌïú ÏóÜÏùå)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Ï∂úÎ†•\n",
    "df_final['Death Cause'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd886640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Config Î°úÎî© Î∞è Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò Ï†ÅÏö© Ï§ë...\n",
      "üß™ [ÌôòÍ≤Ω Í≤ÄÏ¶ù] ÏûêÏó∞ÏÇ¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏãúÏûë (ÎåÄÏÉÅ: 100,000Î™Ö)\n",
      "   üëâ Í≤ÄÏÇ¨Î•º Ï†ÑÌòÄ ÌïòÏßÄ ÏïäÏùÑ ÎïåÏùò Ïïî Î∞úÏÉùÎ•†Í≥º ÏÇ¨ÎßùÎ•†ÏùÑ Ï∏°Ï†ïÌï©ÎãàÎã§.\n",
      "   ... 10,000Î™Ö ÏßÑÌñâ Ï§ë (5.2Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 20,000Î™Ö ÏßÑÌñâ Ï§ë (10.2Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 30,000Î™Ö ÏßÑÌñâ Ï§ë (15.2Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 40,000Î™Ö ÏßÑÌñâ Ï§ë (20.1Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 50,000Î™Ö ÏßÑÌñâ Ï§ë (25.0Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 60,000Î™Ö ÏßÑÌñâ Ï§ë (29.9Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 70,000Î™Ö ÏßÑÌñâ Ï§ë (34.8Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 80,000Î™Ö ÏßÑÌñâ Ï§ë (39.9Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 90,000Î™Ö ÏßÑÌñâ Ï§ë (44.9Ï¥à Í≤ΩÍ≥º)\n",
      "   ... 100,000Î™Ö ÏßÑÌñâ Ï§ë (49.9Ï¥à Í≤ΩÍ≥º)\n",
      "\n",
      "‚úÖ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏôÑÎ£å! (ÏÜåÏöî ÏãúÍ∞Ñ: 49.90Ï¥à)\n",
      "\n",
      "üìä [Natural History Benchmark Result]\n",
      "============================================================\n",
      "1. ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïù∏Ïõê : 100,000 Î™Ö\n",
      "2. ÌèâÍ∑† ÏàòÎ™Ö       : 77.8 ÏÑ∏\n",
      "------------------------------------------------------------\n",
      "3. ÎåÄÏû•Ïïî Î∞úÎ≥ëÎ•†   : 9.58% (ÌèâÏÉù ÏïîÏóê Ìïú Î≤àÏù¥ÎùºÎèÑ Í±∏Î¶¥ ÌôïÎ•†)\n",
      "   - Ï∞∏Í≥†(ÌòÑÏã§)    : ÏïΩ 4% ~ 6% (ÏÑ†ÏßÑÍµ≠ Í∏∞Ï§Ä)\n",
      "------------------------------------------------------------\n",
      "4. ÎåÄÏû•Ïïî ÏÇ¨ÎßùÎ•†   : 1.04% (Í≤ÄÏÇ¨ Ïïà ÌñàÏùÑ Îïå ÏïîÏúºÎ°ú Ï£ΩÏùÑ ÌôïÎ•†)\n",
      "   - Ï∞∏Í≥†(ÌòÑÏã§)    : ÏïΩ 2% ~ 3% (Í≤ÄÏßÑ ÏóÜÏùÑ Ïãú)\n",
      "============================================================\n",
      "üü¢ [ÌåêÏ†ï: Ï†ÅÌï©] Ïïî Î∞úÎ≥ëÎ•†Ïù¥ ÌòÑÏã§Ï†ÅÏù∏ Î≤îÏúÑ(3~10%) ÎÇ¥Ïóê ÏûàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "#application 1. env test\n",
    "#action=waitÏùº Îïå, Ï¶â no screeningÏùº ÎïåÏùò ÌÜµÍ≥ÑÍ∞Ä ÎÇòÏò¥. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def validate_natural_history(env_class, num_patients=100000):\n",
    "    \"\"\"\n",
    "    10Îßå Î™ÖÏùò ÌôòÏûêÎ•º ÎåÄÏÉÅÏúºÎ°ú 'Í≤ÄÏÇ¨ ÏóÜÏù¥(Wait)' ÏãúÎÆ¨Î†àÏù¥ÏÖòÏùÑ ÎèåÎ†§ÏÑú\n",
    "    ÌôòÍ≤ΩÏùò ÏûêÏó∞ÏÇ¨(Natural History) ÌÜµÍ≥ÑÍ∞Ä Ï†ïÏÉÅÏ†ÅÏù∏ÏßÄ Í≤ÄÏ¶ùÌï®.\n",
    "    \"\"\"\n",
    "    env = env_class()\n",
    "    print(f\"üß™ [ÌôòÍ≤Ω Í≤ÄÏ¶ù] ÏûêÏó∞ÏÇ¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏãúÏûë (ÎåÄÏÉÅ: {num_patients:,}Î™Ö)\")\n",
    "    print(\"   üëâ Í≤ÄÏÇ¨Î•º Ï†ÑÌòÄ ÌïòÏßÄ ÏïäÏùÑ ÎïåÏùò Ïïî Î∞úÏÉùÎ•†Í≥º ÏÇ¨ÎßùÎ•†ÏùÑ Ï∏°Ï†ïÌï©ÎãàÎã§.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ÌÜµÍ≥Ñ Î≥ÄÏàò\n",
    "    stats = {\n",
    "        'total_cancer_cases': 0,   # ÏïîÏù¥ Î∞úÎ≥ëÌïú ÏÇ¨Îûå Ïàò (ÏôÑÏπò Ìè¨Ìï®)\n",
    "        'cancer_deaths': 0,        # ÏïîÏúºÎ°ú ÏÇ¨ÎßùÌïú ÏÇ¨Îûå Ïàò\n",
    "        'natural_deaths': 0,       # ÏûêÏó∞ÏÇ¨Ìïú ÏÇ¨Îûå Ïàò\n",
    "        'total_polyps': 0,         # ÌèâÏÉù Î∞úÏÉùÌïú Ï¥ù Ïö©Ï¢Ö Ïàò\n",
    "        'lifespans': []            # ÏàòÎ™Ö Îç∞Ïù¥ÌÑ∞\n",
    "    }\n",
    "    \n",
    "    # 10Îßå Î™Ö Î£®ÌîÑ (ÏãúÍ∞ÑÏù¥ Ï¢Ä Í±∏Î¶¨ÎØÄÎ°ú 1Îßå Î™Ö Îã®ÏúÑÎ°ú Î°úÍ∑∏ Ï∂úÎ†•)\n",
    "    for i in range(num_patients):\n",
    "        if (i+1) % 10000 == 0:\n",
    "            print(f\"   ... {i+1:,}Î™Ö ÏßÑÌñâ Ï§ë ({time.time()-start_time:.1f}Ï¥à Í≤ΩÍ≥º)\")\n",
    "            \n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        has_cancer_history = False # Ïù¥ ÌôòÏûêÍ∞Ä ÌèâÏÉù ÏïîÏóê Í±∏Î¶∞ Ï†ÅÏù¥ ÏûàÎäîÍ∞Ä?\n",
    "        polyps_count = len(env.hidden_polyps) # Ï¥àÍ∏∞ Ïö©Ï¢Ö Ïàò\n",
    "        \n",
    "        while not done:\n",
    "            # Î¨¥Ï°∞Í±¥ ÎåÄÍ∏∞ (Í≤ÄÏÇ¨ Ïïà Ìï®)\n",
    "            action = 0 \n",
    "            \n",
    "            # Step ÏßÑÌñâ\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            \n",
    "            # ÌÜµÍ≥Ñ ÏàòÏßë\n",
    "            if env.hidden_cancer: \n",
    "                has_cancer_history = True\n",
    "            \n",
    "            # ÏÉàÎ°ú ÏÉùÍ∏¥ Ïö©Ï¢Ö Ïπ¥Ïö¥Ìä∏ (Í∑ºÏÇ¨Ïπò: ÌòÑÏû¨ Ïö©Ï¢Ö ÏàòÍ∞Ä ÎäòÏñ¥ÎÇòÎ©¥ Ï≤¥ÌÅ¨)\n",
    "            # Ï†ïÌôïÌûà ÌïòÎ†§Î©¥ env ÎÇ¥Î∂ÄÏóêÏÑú Ïπ¥Ïö¥Ìä∏Ìï¥Ïïº ÌïòÏßÄÎßå, Ïó¨Í∏∞ÏÑ† Í≤ΩÌñ•ÏÑ±Îßå Î¥ÖÎãàÎã§.\n",
    "            if len(env.hidden_polyps) > polyps_count:\n",
    "                polyps_count = len(env.hidden_polyps)\n",
    "\n",
    "        # ÌôòÏûê 1Î™Ö Ï¢ÖÎ£å ÌõÑ ÏßëÍ≥Ñ\n",
    "        stats['lifespans'].append(env.age)\n",
    "        stats['total_polyps'] += polyps_count\n",
    "        if has_cancer_history: stats['total_cancer_cases'] += 1\n",
    "        \n",
    "        if info.get('cause') == 'cancer_death':\n",
    "            stats['cancer_deaths'] += 1\n",
    "        else:\n",
    "            stats['natural_deaths'] += 1\n",
    "\n",
    "    # --- ÏµúÏ¢Ö Í≤ÄÏ¶ù Î¶¨Ìè¨Ìä∏ ---\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏôÑÎ£å! (ÏÜåÏöî ÏãúÍ∞Ñ: {duration:.2f}Ï¥à)\")\n",
    "    \n",
    "    cancer_incidence = (stats['total_cancer_cases'] / num_patients) * 100\n",
    "    cancer_mortality = (stats['cancer_deaths'] / num_patients) * 100\n",
    "    avg_lifespan = np.mean(stats['lifespans'])\n",
    "    \n",
    "    print(\"\\nüìä [Natural History Benchmark Result]\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"1. ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïù∏Ïõê : {num_patients:,} Î™Ö\")\n",
    "    print(f\"2. ÌèâÍ∑† ÏàòÎ™Ö       : {avg_lifespan:.1f} ÏÑ∏\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"3. ÎåÄÏû•Ïïî Î∞úÎ≥ëÎ•†   : {cancer_incidence:.2f}% (ÌèâÏÉù ÏïîÏóê Ìïú Î≤àÏù¥ÎùºÎèÑ Í±∏Î¶¥ ÌôïÎ•†)\")\n",
    "    print(f\"   - Ï∞∏Í≥†(ÌòÑÏã§)    : ÏïΩ 4% ~ 6% (ÏÑ†ÏßÑÍµ≠ Í∏∞Ï§Ä)\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"4. ÎåÄÏû•Ïïî ÏÇ¨ÎßùÎ•†   : {cancer_mortality:.2f}% (Í≤ÄÏÇ¨ Ïïà ÌñàÏùÑ Îïå ÏïîÏúºÎ°ú Ï£ΩÏùÑ ÌôïÎ•†)\")\n",
    "    print(f\"   - Ï∞∏Í≥†(ÌòÑÏã§)    : ÏïΩ 2% ~ 3% (Í≤ÄÏßÑ ÏóÜÏùÑ Ïãú)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Í≤ÄÏ¶ù Î°úÏßÅ\n",
    "    if 3.0 <= cancer_incidence <= 10.0:\n",
    "        print(\"üü¢ [ÌåêÏ†ï: Ï†ÅÌï©] Ïïî Î∞úÎ≥ëÎ•†Ïù¥ ÌòÑÏã§Ï†ÅÏù∏ Î≤îÏúÑ(3~10%) ÎÇ¥Ïóê ÏûàÏäµÎãàÎã§.\")\n",
    "    elif cancer_incidence > 10.0:\n",
    "        print(\"üî¥ [ÌåêÏ†ï: Í≥ºÎã§] Ïïî Î∞úÎ≥ëÎ•†Ïù¥ ÎÑàÎ¨¥ ÎÜíÏäµÎãàÎã§. (Risk Ï†ïÍ∑úÌôî ÎòêÎäî Î∞úÎ≥ëÎ•† ÌååÎùºÎØ∏ÌÑ∞ ÌôïÏù∏ ÌïÑÏöî)\")\n",
    "    else:\n",
    "        print(\"üü° [ÌåêÏ†ï: Í≥ºÏÜå] Ïïî Î∞úÎ≥ëÎ•†Ïù¥ ÎÑàÎ¨¥ ÎÇÆÏäµÎãàÎã§.\")\n",
    "\n",
    "# --- Ïã§Ìñâ ---\n",
    "validate_natural_history(CmostEnv, num_patients=100000)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
