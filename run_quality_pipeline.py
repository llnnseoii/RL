"""
Complete Pipeline: PPO Training â†’ Quality Labeling â†’ Mixed Dataset â†’ CQL Training

ì „ì²´ workflowë¥¼ ì‹¤í–‰í•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
"""

import numpy as np
from parameters import SimulationParameters

# ìƒˆë¡œ ìƒì„±í•œ ëª¨ë“ˆë“¤
from ppo_variants import train_and_collect_all_variants
from quality_dataset import MixedDatasetGenerator, extract_transitions_from_episodes
from cql_optimizer import CQLOptimizer


def run_complete_pipeline():
    """
    Complete Pipeline ì‹¤í–‰
    
    ë‹¨ê³„:
    1. PPO í•™ìŠµ + Episode ìˆ˜ì§‘ (ê° variantë³„ 1000 training, 1000 collection)
    2. Quality ë¼ë²¨ë§ (GOOD/MEDIUM/BAD)
    3. Mixed Dataset ìƒì„± (50% good, 30% medium, 20% bad)
    4. CQL í•™ìŠµ
    """
    print("="*70)
    print("  Complete PPOâ†’CQL Pipeline with Actual Training")
    print("  Step 1: Train 3 PPO Variants + Collect Episodes")
    print("  Step 2: Label Quality (GOOD/MEDIUM/BAD)")
    print("  Step 3: Create Mixed Dataset (50/30/20)")
    print("  Step 4: Train CQL with Mixed Data")
    print("="*70)
    
    # Parameters
    params = SimulationParameters('settings.ini')
    
    # ========== Step 1: Train PPO & Collect Episodes ==========
    print("\n" + "="*70)
    print("STEP 1: Training PPO Variants & Collecting Episodes")
    print("="*70)
    print("  - Conservative PPO: 1000 train â†’ 1000 collect")
    print("  - Balanced PPO: 1000 train â†’ 1000 collect")
    print("  - Aggressive PPO: 1000 train â†’ 1000 collect")
    print("  â±ï¸  ì˜ˆìƒ ì‹œê°„: ~60ë¶„")
    print("="*70)
    
    all_episodes = train_and_collect_all_variants(
        params,
        episodes_per_variant=1000,    # ìˆ˜ì§‘í•  episodes
        training_episodes=1000,        # PPO í•™ìŠµ episodes
        save_path='diverse_ppo_data.pkl'
    )
    
    print(f"\nâœ… ì´ {len(all_episodes)} episodes ìˆ˜ì§‘ ì™„ë£Œ")
    
    # ========== Step 2: Quality Labeling ==========
    print("\n" + "="*70)
    print("STEP 2: Quality Labeling")
    print("="*70)
    
    generator = MixedDatasetGenerator(
        good_ratio=0.5,
        medium_ratio=0.3,
        bad_ratio=0.2
    )
    
    categorized = generator.collect_and_label_episodes(all_episodes)
    
    # ========== Step 3: Create Mixed Dataset ==========
    print("\n" + "="*70)
    print("STEP 3: Creating Mixed Dataset")
    print("="*70)
    
    total_dataset_size = 3000
    mixed_episodes = generator.create_mixed_dataset(
        categorized,
        total_size=total_dataset_size
    )
    
    # Save mixed dataset
    generator.save_dataset(mixed_episodes, 'mixed_dataset_50_30_20.pkl')
    
    # Extract transitions for CQL
    print("\nğŸ”„ Extracting transitions from episodes...")
    all_transitions = extract_transitions_from_episodes(mixed_episodes)
    print(f"âœ… {len(all_transitions)} transitions ì¶”ì¶œ ì™„ë£Œ")
    
    # ========== Step 4: Train CQL ==========
    print("\n" + "="*70)
    print("STEP 4: Training CQL with Mixed Dataset")
    print("="*70)
    
    cql = CQLOptimizer('settings.ini')
    cql.train_from_transitions(
        transitions=all_transitions,
        epochs=100,
        batch_size=256,
        alpha=1.0  # CQL penalty weight
    )
    
    # Save CQL model
    cql.save_model('cql_from_mixed_50_30_20.pth')
    
    print("\n" + "="*70)
    print("  âœ… Complete Pipeline ì™„ë£Œ!")
    print("="*70)
    print(f"  ğŸ“‚ Diverse Episodes: diverse_ppo_data.pkl")
    print(f"  ğŸ“‚ PPO Models: ppo_conservative.pth, ppo_balanced.pth, ppo_aggressive.pth")
    print(f"  ğŸ“‚ Mixed Dataset: mixed_dataset_50_30_20.pkl")
    print(f"  ğŸ“‚ CQL Model: cql_from_mixed_50_30_20.pth")
    print("="*70)


def run_step_by_step():
    """ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)"""
    import sys
    
    print("\në‹¨ê³„ë³„ ì‹¤í–‰ ëª¨ë“œ")
    print("1. PPO í•™ìŠµ + ë°ì´í„° ìˆ˜ì§‘ (Conservative, Balanced, Aggressive)")
    print("2. Quality Labelingë§Œ (ê¸°ì¡´ diverse_ppo_data.pkl ì‚¬ìš©)")
    print("3. Mixed Dataset ìƒì„±ë§Œ")
    print("4. CQL í•™ìŠµë§Œ")
    print("5. ì „ì²´ ì‹¤í–‰")
    
    choice = input("\nì„ íƒ (1-5): ")
    
    params = SimulationParameters('settings.ini')
    
    if choice == '1':
        print("\nğŸ“ PPO í•™ìŠµ + ë°ì´í„° ìˆ˜ì§‘...")
        all_episodes = train_and_collect_all_variants(
            params, 
            episodes_per_variant=1000,
            training_episodes=1000
        )
        
    elif choice == '2':
        print("\nğŸ·ï¸  Quality Labeling...")
        import pickle
        with open('diverse_ppo_data.pkl', 'rb') as f:
            all_episodes = pickle.load(f)
        
        generator = MixedDatasetGenerator(0.5, 0.3, 0.2)
        categorized = generator.collect_and_label_episodes(all_episodes)
        
        # Stats
        for quality in ['GOOD', 'MEDIUM', 'BAD']:
            if quality in categorized:
                rewards = [e['total_reward'] for e in categorized[quality]]
                costs = [e['total_cost'] for e in categorized[quality]]
                print(f"  {quality}: Avg Reward = {np.mean(rewards):.2f}, Avg Cost = ${np.mean(costs):.0f}")
        
    elif choice == '3':
        print("\nğŸ² Mixed Dataset ìƒì„±...")
        import pickle
        with open('diverse_ppo_data.pkl', 'rb') as f:
            all_episodes = pickle.load(f)
        
        generator = MixedDatasetGenerator(0.5, 0.3, 0.2)
        categorized = generator.collect_and_label_episodes(all_episodes)
        mixed = generator.create_mixed_dataset(categorized, 3000)
        generator.save_dataset(mixed, 'mixed_dataset_50_30_20.pkl')
        
    elif choice == '4':
        print("\nğŸ¤– CQL í•™ìŠµ...")
        import pickle
        with open('mixed_dataset_50_30_20.pkl', 'rb') as f:
            mixed_episodes = pickle.load(f)
        
        transitions = extract_transitions_from_episodes(mixed_episodes)
        cql = CQLOptimizer('settings.ini')
        cql.train_from_transitions(transitions, epochs=100)
        cql.save_model('cql_from_mixed_50_30_20.pth')
        
    elif choice == '5':
        run_complete_pipeline()
    
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--step':
        run_step_by_step()
    else:
        run_complete_pipeline()
